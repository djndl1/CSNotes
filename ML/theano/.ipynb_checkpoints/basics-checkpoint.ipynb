{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano as th\n",
    "import theano.tensor as T\n",
    "import theano.d3viz\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Symbolic variables play the role of placeholders, as a starting point to build graph of numerical operations and represent intermediate or output results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(x + y)'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y, z = T.matrices('x', 'y', 'z')\n",
    "z = x + y\n",
    "th.printing.pprint(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elemwise{add,no_inplace} [id A] ''   \n",
      " |x [id B]\n",
      " |y [id C]\n"
     ]
    }
   ],
   "source": [
    "th.printing.debugprint(z)\n",
    "# prints the pre-compilation graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_add = th.function([x, y], [z])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[2., 2.],\n",
       "        [4., 7.]], dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_add([[1, 2],\n",
    "      [1, 3]], [[1, 0], \n",
    "               [3, 4]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HostFromGpu(gpuarray) [id A] ''   3\n",
      " |GpuElemwise{Add}[(0, 0)]<gpuarray> [id B] ''   2\n",
      "   |GpuFromHost<None> [id C] ''   1\n",
      "   | |x [id D]\n",
      "   |GpuFromHost<None> [id E] ''   0\n",
      "     |y [id F]\n"
     ]
    }
   ],
   "source": [
    "th.printing.debugprint(f_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file is available at /home/djn/.theano/compiledir_Linux-5.4-bpo.2-amd64-x86_64-with-debian-10.2--3.7.3-64/theano.pydotprint.opencl0:0.png\n"
     ]
    }
   ],
   "source": [
    "th.printing.pydotprint(f_add)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "th.d3viz.d3viz(f_add, 'f_add')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = z * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HostFromGpu(gpuarray) [id A] ''   3\n",
      " |GpuElemwise{Composite{((i0 + i1) * i0)}}[(0, 0)]<gpuarray> [id B] ''   2\n",
      "   |GpuFromHost<None> [id C] ''   1\n",
      "   | |x [id D]\n",
      "   |GpuFromHost<None> [id E] ''   0\n",
      "     |y [id F]\n"
     ]
    }
   ],
   "source": [
    "th.printing.debugprint(th.function([x, y], z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[1., 1.],\n",
       "        [1., 1.]], dtype=float32)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f_add(np.ones((2, 2), dtype=th.config.floatX), \n",
    "      np.zeros((2, 2), dtype=th.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Bad input argument to theano function with name \"<ipython-input-4-3e217efb2c0c>:1\" at index 0 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-a631279c11e2>\", line 1, in <module>\n    x, y, z = T.matrices('x', 'y', 'z')\nTensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\". Value: \"array([[1., 1.],\n       [1., 1.]])\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9ad45a43b45c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m f_add(np.ones((2, 2)), \n\u001b[0;32m----> 2\u001b[0;31m       np.zeros((2, 2)))\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# precision error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    811\u001b[0m                         s.storage[0] = s.type.filter(\n\u001b[1;32m    812\u001b[0m                             \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m                             allow_downcast=s.allow_downcast)\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3/dist-packages/theano/tensor/type.py\u001b[0m in \u001b[0;36mfilter\u001b[0;34m(self, data, strict, allow_downcast)\u001b[0m\n\u001b[1;32m    138\u001b[0m                             \u001b[0;34m'\"function\". Value: \"%s\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                             % (self, data.dtype, self.dtype, repr(data)))\n\u001b[0;32m--> 140\u001b[0;31m                         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr_msg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    141\u001b[0m                 elif (allow_downcast is None and\n\u001b[1;32m    142\u001b[0m                         \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mfloat\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Bad input argument to theano function with name \"<ipython-input-4-3e217efb2c0c>:1\" at index 0 (0-based).  \nBacktrace when that variable is created:\n\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/usr/lib/python3/dist-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/usr/lib/python3/dist-packages/ipykernel/ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/usr/lib/python3/dist-packages/ipykernel/zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2714, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2818, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/usr/lib/python3/dist-packages/IPython/core/interactiveshell.py\", line 2878, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-a631279c11e2>\", line 1, in <module>\n    x, y, z = T.matrices('x', 'y', 'z')\nTensorType(float32, matrix) cannot store a value of dtype float64 without risking loss of precision. If you do not mind this loss, you can: 1) explicitly cast your data to float32, or 2) set \"allow_input_downcast=True\" when calling \"function\". Value: \"array([[1., 1.],\n       [1., 1.]])\""
     ]
    }
   ],
   "source": [
    "f_add(np.ones((2, 2)), \n",
    "      np.zeros((2, 2)))\n",
    "# precision error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0.],\n",
       "       [0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.zeros((2, 3))\n",
    "a.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0.],\n",
       "       [0., 1., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = T.identity_like(a)\n",
    "b.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = T.arange(10)\n",
    "c.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.ndim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'int64'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorType(int64, vector)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 6, 4, 2, 0],\n",
       "       [9, 7, 5, 3, 1]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.arange(10).reshape((5, 2))[::-1].T.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.,  2.], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  Condition operator\n",
    "cond = T.vector('cond')\n",
    "x, y = T.vectors('x', 'y')\n",
    "z = T.switch(cond, x, y)\n",
    "z.eval({cond: [1, 0], x: [10, 10], y:[3, 2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(5, dtype=int8)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z = th.ifelse.ifelse(1, 5 ,4)\n",
    "z.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is good practice to always cast float arrays to the `theano.config.floatX` type using `dtype=theano.config.floatX` or `.astype(theano.config.floatX)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tranfer(device)` enables us to move the data from one device to another one, particularly useful when parts of the graph have to be executed on different devices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HostFromGpu(gpuarray) [id A] ''   2\n",
      " |GpuElemwise{Sqr}[(0, 0)]<gpuarray> [id B] ''   1\n",
      "   |GpuFromHost<None> [id C] ''   0\n",
      "     |a [id D]\n"
     ]
    }
   ],
   "source": [
    "a = T.matrix('a')\n",
    "b = a ** 2\n",
    "sq = th.function([a], b)\n",
    "th.printing.debugprint(sq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GpuElemwise{Sqr}[(0, 0)]<gpuarray> [id A] ''   1\n",
      " |GpuFromHost<None> [id B] ''   0\n",
      "   |a [id C]\n"
     ]
    }
   ],
   "source": [
    "b = b.transfer(None)\n",
    "sq = th.function([a], b)\n",
    "th.printing.debugprint(sq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shared variables are a concept between numerical values and symbolic variables. This leads to better performance on the GPU by avoiding transfers. By default, shared variables are created on the default device, except for scalar integer values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TensorType(int64, scalar)>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "th.shared(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions and automatic differentiation\n",
    "a = T.matrix()\n",
    "ex = th.function([a], [T.exp(a), T.log(a), a**2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.74656826, 0.41549572, 0.99933714],\n",
       "        [0.097233  , 0.81948423, 1.8694875 ],\n",
       "        [0.17030624, 0.3338887 , 0.4930014 ]], dtype=float32),\n",
       " array([[        nan,         nan,         nan],\n",
       "        [        nan,         nan, -0.46894115],\n",
       "        [        nan,         nan,         nan]], dtype=float32),\n",
       " array([[8.5420690e-02, 7.7138096e-01, 4.3969865e-07],\n",
       "        [5.4319067e+00, 3.9632872e-02, 3.9145595e-01],\n",
       "        [3.1334562e+00, 1.2032939e+00, 5.0019306e-01]], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex(np.random.randn(3, 3).astype(th.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = th.shared(1.0)\n",
    "x = T.scalar('x')\n",
    "mul = th.function([x], updates=[(w, w*x)])\n",
    "# updates, used to set new values to shared variables once the expression has been evaluated\n",
    "mul(4)\n",
    "# and can be used as an internal state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(4.)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# givens parameter: change the value of any symbolic variable in the graph\n",
    "# without changing the graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output file is available at /home/djn/.theano/compiledir_Linux-5.4-bpo.2-amd64-x86_64-with-debian-10.2--3.7.3-64/theano.pydotprint.opencl0:0.png\n"
     ]
    }
   ],
   "source": [
    "a = T.scalar()\n",
    "pow = a**2\n",
    "g = th.grad(pow, a)\n",
    "th.printing.pydotprint(th.function([a], g))\n",
    "# It is only possible to take the gradient of a scalar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A traditional Python `for` loop isn't compiled, so it will not be optimized wit parallel and algebra libraries, cannot be automatically differentiated and introduces costly data transfer if the computation subgraph has been optimized for GPU.\n",
    "\n",
    "The `scan` operator is useful to implement array loops, reductions, maps, multi-dimensional derivatives such as Jacobian or Hessian and recurrences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2., 2., 2.],\n",
       "       [2., 2., 2.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.matrix()\n",
    "b = T.matrix()\n",
    "def fn(x) : return x + 1 # called once and compiled\n",
    "results, updates = th.scan(fn, sequences=a)\n",
    "# sequences are the lists of input variables to loop over\n",
    "# The scan operator runs the `fn` function for n_steps\n",
    "f = th.function([a], results, updates=updates)\n",
    "f(np.ones((2, 3)).astype(th.config.floatX))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  1.  4.  9. 16. 25. 36. 49. 64. 81.]\n",
      "[0.000e+00 1.000e+00 1.600e+01 8.100e+01 2.560e+02 6.250e+02 1.296e+03\n",
      " 2.401e+03 4.096e+03 6.561e+03]\n"
     ]
    }
   ],
   "source": [
    "k = T.iscalar(\"k\")\n",
    "A = T.vector(\"A\")\n",
    "\n",
    "# Symbolic description of the result\n",
    "result, updates = th.scan(fn=lambda prior_result, A: prior_result * A,\n",
    "                              outputs_info=T.ones_like(A),\n",
    "                              non_sequences=A,\n",
    "                              n_steps=k)\n",
    "\n",
    "# We only care about A**k, but scan has provided us with A**1 through A**k.\n",
    "# Discard the values that we don't care about. Scan is smart enough to\n",
    "# notice this and not waste memory saving them.\n",
    "final_result = result[-1]\n",
    "\n",
    "# compiled function that returns A**k\n",
    "power = th.function(inputs=[A,k], outputs=final_result, updates=updates)\n",
    "\n",
    "print(power(range(10),2))\n",
    "print(power(range(10),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 2., 3., 4., 5.])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = T.vector()\n",
    "s0 = T.scalar('s0')\n",
    "results, updates = th.scan(fn=lambda cur_elem, prior: cur_elem + prior,\n",
    "                          outputs_info=s0,\n",
    "                          sequences=a)\n",
    "f = th.function([a, s0], results, updates=updates)\n",
    "f([1, 1, 1, 1, 1], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
